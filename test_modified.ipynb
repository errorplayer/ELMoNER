{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 备用命令行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.13.1\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 345.2MB 82.7MB/s eta 0:00:01     | 37.0MB 86.9MB/s eta 0:00:04         | 56.4MB 82.2MB/s eta 0:00:04███                          | 65.9MB 47.7MB/s eta 0:00:068MB 84.0MB/s eta 0:00:04 93.4MB 63.5MB/s eta 0:00:04��████▏                      | 98.9MB 64.4MB/s eta 0:00:04�███████                    | 130.4MB 102.8MB/s eta 0:00:0384.5MB/s eta 0:00:03███▋                  | 146.4MB 98.6MB/s eta 0:00:03   44% |██████████████▍                 | 154.9MB 84.0MB/s eta 0:00:03   45% |██████████████▋                 | 158.0MB 67.8MB/s eta 0:00:03   | 165.7MB 86.1MB/s eta 0:00:03   52% |████████████████▊               | 180.3MB 56.0MB/s eta 0:00:03��████████               | 184.1MB 72.4MB/s eta 0:00:03:02[K    55% |█████████████████▊              | 190.7MB 85.3MB/s eta 0:00:02[K    56% |██████████████████              | 195.0MB 51.1MB/s eta 0:00:03�███████▋             | 200.8MB 78.3MB/s eta 0:00:02 |████████████████████▉           | 224.8MB 85.1MB/s eta 0:00:02 | 231.8MB 105.3MB/s eta 0:00:02s eta 0:00:02█████▊         | 245.4MB 77.8MB/s eta 0:00:02██████         | 248.9MB 64.1MB/s eta 0:00:0252.0MB 88.4MB/s eta 0:00:02��████████████████▎    | 294.3MB 90.9MB/s eta 0:00:01�███████████████████████████▎   | 304.6MB 102.0MB/s eta 0:00:01.8MB 98.2MB/s eta 0:00:01███████▍ | 327.4MB 32.4MB/s eta 0:00:01███████████████████████ | 333.5MB 42.4MB/s eta 0:00:01�█████████████████▊| 342.7MB 50.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow-gpu==1.13.1)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 102.7MB/s ta 0:00:01              | 204kB 102.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow-gpu==1.13.1)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 100.8MB/s ta 0:00:01   70% |██████████████████████▊         | 2.3MB 72.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: mock>=2.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1)\n",
      "Requirement already satisfied: setuptools in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
      "  Found existing installation: tensorflow-estimator 1.14.0\n",
      "    Uninstalling tensorflow-estimator-1.14.0:\n",
      "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
      "  Found existing installation: tensorboard 1.14.0\n",
      "    Uninstalling tensorboard-1.14.0:\n",
      "      Successfully uninstalled tensorboard-1.14.0\n",
      "  Found existing installation: tensorflow-gpu 1.14.0\n",
      "    Uninstalling tensorflow-gpu-1.14.0:\n",
      "      Successfully uninstalled tensorflow-gpu-1.14.0\n",
      "Successfully installed tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f example.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: line 0: cd: model: No such file or directory\r\n",
      "data  data.py  elmo.py\tmodel1\t__pycache__\r\n"
     ]
    }
   ],
   "source": [
    "!cd model; dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  data.py  elmo.py\tmodel3\t__pycache__\r\n"
     ]
    }
   ],
   "source": [
    "!dir "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 华为云搬运文件至当前notebook dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moxing as mox\n",
    "\n",
    "# mox.file.copy_parallel('obs://class-1275-41780/Lab-1799/mode*******91/data', '/home/ma-user/work/data')\n",
    "mox.file.copy_parallel('obs://class-1275-41780/Lab-1799/model********del3', '/home/ma-user/work/model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1:  使用预训练模型进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 1: 引入包，参数设置，类加载\n",
    "\n",
    "> 需要将emlo.py 和 data.py 两个文件放在同目录下                  \n",
    "> 需要将data文件夹放在同目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "colab_type": "code",
    "id": "6kik532ElbpO",
    "outputId": "6f057f32-f494-4fa5-92f5-e0cc6715feb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载语料./data/example.train, 语料数量18404\n",
      "成功加载语料./data/example.test, 语料数量4558\n",
      "成功加载语料./data/example.dev, 语料数量4384\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "from elmo import ELMo\n",
    "from data import NERData\n",
    "import os\n",
    "\n",
    "total_epoch = 5000\n",
    "hidden_size = 200\n",
    "vocab_size = 5000\n",
    "max_length = 128\n",
    "entity_class = 7\n",
    "\n",
    "batch_size = 1    # 跟训练的区别\n",
    "\n",
    "ner = NERData(batch_size, max_length)\n",
    "elmo = ELMo(batch_size, hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 2: 顶层softmax layer函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "twFdg_xMlbpV"
   },
   "outputs": [],
   "source": [
    "def network(X):\n",
    "#     with tf.variable_scope(reuse=tf.AUTO_REUSE):\n",
    "        w = tf.get_variable(\"fcn_w\", [1, hidden_size, entity_class + 1])\n",
    "        b = tf.get_variable(\"fcn_b\", [entity_class + 1])\n",
    "        # 这里输出维度用entity_class + 1而不是entity_class，因为输出里除了7类实体，还有一类用来表示每个句子补齐的<PAD>位\n",
    "        w_tile = tf.tile(w, [batch_size, 1, 1])\n",
    "\n",
    "        logists = tf.nn.softmax(tf.nn.xw_plus_b(X, w_tile, b), name=\"logists\")\n",
    "        return logists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step 3: 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "C_HCR-RKlbpZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:28: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:28: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:36: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:31: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:56: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f8a302d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f8a302d30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f8a302d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f8a302d30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f466cfcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f466cfcf8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f466cfcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f466cfcf8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f562fcb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f562fcb00>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f562fcb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f562fcb00>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f4494b518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f4494b518>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f4494b518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f4494b518>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model3/model3-14301\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"X\")\n",
    "length = tf.placeholder(shape=[batch_size], dtype=tf.int32, name=\"length\")\n",
    "dropout = tf.placeholder(shape=[], dtype=tf.float32, name=\"dropout\")\n",
    "\n",
    "elmo_vector = elmo.elmo(X, length, dropout)\n",
    "logists = network(elmo_vector)\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "model_dir = \"./model3\"\n",
    "saver = tf.train.Saver()\n",
    "check_point = tf.train.get_checkpoint_state(model_dir)\n",
    "saver.restore(sess, check_point.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnkfT4dalbpd"
   },
   "source": [
    "#### step 4: 查看elmo各层的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "7BbswS2glbpe",
    "outputId": "95d2ab2c-75ca-4713-a8e8-34a49cbabedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding层: 0.017066773\n",
      "forward_1层: 0.15887623\n",
      "forward_2层: 0.3802379\n",
      "backward_1层: 0.23893026\n",
      "backward_2层: 0.20488887\n"
     ]
    }
   ],
   "source": [
    "_X, _length, _targets = ner.get_dev_data(1)\n",
    "fd = {X: _X, length: _length, dropout: 1.}\n",
    "weights = sess.run(tf.nn.softmax(elmo.weights), feed_dict=fd)\n",
    "print(\"embedding层:\", weights[0])\n",
    "print(\"forward_1层:\", weights[1])\n",
    "print(\"forward_2层:\", weights[2])\n",
    "print(\"backward_1层:\", weights[3])\n",
    "print(\"backward_2层:\", weights[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ta5ZVr5tlbpi"
   },
   "source": [
    "#### step 5: 用来自不同领域的句子进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 988
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ucSPk56bo16J",
    "outputId": "36c32a8b-cf24-429f-bf36-8cc1f6822aed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('中', 'B-ORG'),\n",
       " ('国', 'I-ORG'),\n",
       " ('石', 'I-ORG'),\n",
       " ('油', 'I-ORG'),\n",
       " ('大', 'I-ORG'),\n",
       " ('学', 'I-ORG'),\n",
       " ('（', 'O'),\n",
       " ('北', 'B-LOC'),\n",
       " ('京', 'I-LOC'),\n",
       " ('）', 'I-LOC'),\n",
       " ('克', 'I-LOC'),\n",
       " ('拉', 'I-LOC'),\n",
       " ('玛', 'I-PER'),\n",
       " ('依', 'I-ORG'),\n",
       " ('校', 'I-ORG'),\n",
       " ('区', 'O'),\n",
       " ('设', 'O'),\n",
       " ('有', 'O'),\n",
       " ('石', 'O'),\n",
       " ('油', 'O'),\n",
       " ('工', 'O'),\n",
       " ('程', 'O'),\n",
       " ('、', 'O'),\n",
       " ('地', 'O'),\n",
       " ('质', 'O'),\n",
       " ('、', 'O'),\n",
       " ('储', 'O'),\n",
       " ('运', 'O'),\n",
       " ('等', 'O'),\n",
       " ('石', 'O'),\n",
       " ('油', 'O'),\n",
       " ('大', 'O'),\n",
       " ('学', 'O'),\n",
       " ('传', 'O'),\n",
       " ('统', 'O'),\n",
       " ('优', 'O'),\n",
       " ('势', 'O'),\n",
       " ('专', 'O'),\n",
       " ('业', 'O'),\n",
       " ('，', 'O'),\n",
       " ('并', 'O'),\n",
       " ('开', 'O'),\n",
       " ('展', 'O'),\n",
       " ('面', 'O'),\n",
       " ('向', 'O'),\n",
       " ('中', 'B-LOC'),\n",
       " ('亚', 'I-LOC'),\n",
       " ('地', 'O'),\n",
       " ('区', 'O'),\n",
       " ('的', 'O'),\n",
       " ('留', 'O'),\n",
       " ('学', 'O'),\n",
       " ('生', 'O'),\n",
       " ('教', 'O'),\n",
       " ('育', 'O'),\n",
       " ('。', 'O')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"中国石油大学（北京）克拉玛依校区设有石油工程、地质、储运等石油大学传统优势专业，并开展面向中亚地区的留学生教育。\"\n",
    "_X, _length = ner.sentence_encode(s)\n",
    "fd = {X: _X, length: _length, dropout: 1.}\n",
    "result = sess.run(logists, feed_dict=fd)\n",
    "result_entities = ner.entities_decode(result[0].argmax(axis=1))\n",
    "list(zip(s, result_entities))[:_length[0]][:len(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tewK8hsulbpj",
    "outputId": "32327085-0942-46c5-edd7-bd4dcbe37c3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('李', 'B-PER'),\n",
       " ('克', 'I-PER'),\n",
       " ('强', 'I-PER'),\n",
       " ('来', 'O'),\n",
       " ('到', 'O'),\n",
       " ('位', 'O'),\n",
       " ('于', 'O'),\n",
       " ('江', 'B-LOC'),\n",
       " ('西', 'I-LOC'),\n",
       " ('省', 'I-LOC'),\n",
       " ('赣', 'B-LOC'),\n",
       " ('州', 'I-LOC'),\n",
       " ('市', 'I-LOC'),\n",
       " ('于', 'O'),\n",
       " ('都', 'O'),\n",
       " ('县', 'B-LOC'),\n",
       " ('的', 'O'),\n",
       " ('梓', 'B-LOC'),\n",
       " ('山', 'I-LOC'),\n",
       " ('镇', 'I-LOC'),\n",
       " ('潭', 'I-LOC'),\n",
       " ('头', 'I-LOC'),\n",
       " ('村', 'I-LOC'),\n",
       " ('看', 'O'),\n",
       " ('望', 'O'),\n",
       " ('慰', 'O'),\n",
       " ('问', 'O'),\n",
       " ('群', 'O'),\n",
       " ('众', 'O')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"李克强来到位于江西省赣州市于都县的梓山镇潭头村看望慰问群众\"\n",
    "_X, _length = ner.sentence_encode(s)\n",
    "fd = {X: _X, length: _length, dropout: 1.}\n",
    "result = sess.run(logists, feed_dict=fd)\n",
    "result_entities = ner.entities_decode(result[0].argmax(axis=1))\n",
    "list(zip(s, result_entities))[:_length[0]][:len(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cVI7XZIBlbpn",
    "outputId": "f385b8fe-8d0e-4599-d996-64166bdedf7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('多', 'O'),\n",
       " ('名', 'O'),\n",
       " ('白', 'B-ORG'),\n",
       " ('宫', 'I-ORG'),\n",
       " ('官', 'O'),\n",
       " ('员', 'O'),\n",
       " ('对', 'O'),\n",
       " ('媒', 'O'),\n",
       " ('体', 'O'),\n",
       " ('表', 'O'),\n",
       " ('示', 'O'),\n",
       " ('，', 'O'),\n",
       " ('美', 'B-LOC'),\n",
       " ('国', 'I-LOC'),\n",
       " ('总', 'O'),\n",
       " ('统', 'O'),\n",
       " ('特', 'B-PER'),\n",
       " ('朗', 'I-LOC'),\n",
       " ('普', 'I-PER'),\n",
       " ('不', 'O'),\n",
       " ('准', 'O'),\n",
       " ('备', 'O'),\n",
       " ('续', 'O'),\n",
       " ('签', 'O'),\n",
       " ('即', 'O'),\n",
       " ('将', 'O'),\n",
       " ('到', 'O'),\n",
       " ('期', 'O'),\n",
       " ('的', 'O'),\n",
       " ('美', 'B-LOC'),\n",
       " ('俄', 'B-LOC'),\n",
       " ('《', 'O'),\n",
       " ('新', 'O'),\n",
       " ('削', 'O'),\n",
       " ('减', 'O'),\n",
       " ('战', 'O'),\n",
       " ('略', 'O'),\n",
       " ('武', 'O'),\n",
       " ('器', 'O'),\n",
       " ('条', 'O'),\n",
       " ('约', 'O'),\n",
       " ('》', 'O'),\n",
       " ('，', 'O'),\n",
       " ('而', 'O'),\n",
       " ('是', 'O'),\n",
       " ('想', 'O'),\n",
       " ('推', 'O'),\n",
       " ('动', 'O'),\n",
       " ('达', 'O'),\n",
       " ('成', 'O'),\n",
       " ('一', 'O'),\n",
       " ('项', 'O'),\n",
       " ('包', 'O'),\n",
       " ('括', 'O'),\n",
       " ('中', 'B-LOC'),\n",
       " ('国', 'I-LOC'),\n",
       " ('在', 'O'),\n",
       " ('内', 'O'),\n",
       " ('的', 'O'),\n",
       " ('新', 'O'),\n",
       " ('条', 'O'),\n",
       " ('约', 'O')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"多名白宫官员对媒体表示，美国总统特朗普不准备续签即将到期的美俄《新削减战略武器条约》，而是想推动达成一项包括中国在内的新条约\"\n",
    "_X, _length = ner.sentence_encode(s)\n",
    "fd = {X: _X, length: _length, dropout: 1.}\n",
    "result = sess.run(logists, feed_dict=fd)\n",
    "result_entities = ner.entities_decode(result[0].argmax(axis=1))\n",
    "list(zip(s, result_entities))[:_length[0]][:len(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CgwS5TW2lbpr",
    "outputId": "f9d8236c-a9e0-4bdb-cfd0-01227567da5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('小', 'B-PER'),\n",
       " ('罗', 'B-PER'),\n",
       " ('伯', 'I-PER'),\n",
       " ('特', 'I-PER'),\n",
       " ('·', 'I-PER'),\n",
       " ('唐', 'I-PER'),\n",
       " ('尼', 'I-PER'),\n",
       " ('专', 'O'),\n",
       " ('门', 'O'),\n",
       " ('为', 'O'),\n",
       " ('漫', 'O'),\n",
       " ('威', 'O'),\n",
       " ('总', 'O'),\n",
       " ('裁', 'O'),\n",
       " ('凯', 'B-PER'),\n",
       " ('文', 'I-PER'),\n",
       " ('费', 'I-PER'),\n",
       " ('奇', 'I-PER'),\n",
       " ('颁', 'O'),\n",
       " ('发', 'O'),\n",
       " ('特', 'O'),\n",
       " ('别', 'O'),\n",
       " ('大', 'O'),\n",
       " ('奖', 'O'),\n",
       " ('，', 'O'),\n",
       " ('他', 'O'),\n",
       " ('在', 'O'),\n",
       " ('介', 'O'),\n",
       " ('绍', 'O'),\n",
       " ('凯', 'B-PER'),\n",
       " ('文', 'I-PER'),\n",
       " ('费', 'I-PER'),\n",
       " ('奇', 'I-PER'),\n",
       " ('的', 'O'),\n",
       " ('时', 'O'),\n",
       " ('候', 'O'),\n",
       " ('说', 'O'),\n",
       " ('道', 'O'),\n",
       " ('“', 'O'),\n",
       " ('我', 'O'),\n",
       " ('要', 'O'),\n",
       " ('感', 'O'),\n",
       " ('谢', 'O'),\n",
       " ('凯', 'O'),\n",
       " ('文', 'O'),\n",
       " ('，', 'O'),\n",
       " ('他', 'O'),\n",
       " ('在', 'O'),\n",
       " ('我', 'O'),\n",
       " ('的', 'O'),\n",
       " ('低', 'O'),\n",
       " ('谷', 'O'),\n",
       " ('期', 'O'),\n",
       " ('认', 'O'),\n",
       " ('可', 'O'),\n",
       " ('我', 'O'),\n",
       " ('“', 'O')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"小罗伯特·唐尼专门为漫威总裁凯文费奇颁发特别大奖，他在介绍凯文费奇的时候说道“我要感谢凯文，他在我的低谷期认可我“\"\n",
    "_X, _length = ner.sentence_encode(s)\n",
    "fd = {X: _X, length: _length, dropout: 1.}\n",
    "result = sess.run(logists, feed_dict=fd)\n",
    "result_entities = ner.entities_decode(result[0].argmax(axis=1))\n",
    "list(zip(s, result_entities))[:_length[0]][:len(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9FMLNbe-lbpv",
    "outputId": "73937453-dfb5-41e6-afc0-e37c96e013ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('马', 'B-PER'),\n",
       " ('苏', 'I-PER'),\n",
       " ('、', 'O'),\n",
       " ('周', 'B-PER'),\n",
       " ('冬', 'I-PER'),\n",
       " ('雨', 'I-PER'),\n",
       " ('、', 'O'),\n",
       " ('林', 'B-PER'),\n",
       " ('更', 'I-PER'),\n",
       " ('新', 'I-PER'),\n",
       " ('、', 'O'),\n",
       " ('霍', 'B-PER'),\n",
       " ('建', 'I-PER'),\n",
       " ('华', 'I-PER'),\n",
       " ('都', 'O'),\n",
       " ('被', 'O'),\n",
       " ('拍', 'O'),\n",
       " ('到', 'O'),\n",
       " ('出', 'O'),\n",
       " ('现', 'O'),\n",
       " ('在', 'O'),\n",
       " ('周', 'B-PER'),\n",
       " ('杰', 'I-PER'),\n",
       " ('伦', 'I-PER'),\n",
       " ('的', 'O'),\n",
       " ('演', 'O'),\n",
       " ('唱', 'O'),\n",
       " ('会', 'O'),\n",
       " ('上', 'O'),\n",
       " ('，', 'O'),\n",
       " ('此', 'O'),\n",
       " ('外', 'O'),\n",
       " ('，', 'O'),\n",
       " ('林', 'B-PER'),\n",
       " ('俊', 'I-PER'),\n",
       " ('杰', 'I-PER'),\n",
       " ('和', 'O'),\n",
       " ('陈', 'B-PER'),\n",
       " ('奕', 'I-PER'),\n",
       " ('迅', 'I-PER'),\n",
       " ('等', 'O'),\n",
       " ('超', 'O'),\n",
       " ('级', 'O'),\n",
       " ('巨', 'O'),\n",
       " ('星', 'O'),\n",
       " ('也', 'O'),\n",
       " ('都', 'O'),\n",
       " ('作', 'O'),\n",
       " ('为', 'O'),\n",
       " ('演', 'O'),\n",
       " ('唱', 'O'),\n",
       " ('会', 'O'),\n",
       " ('嘉', 'O'),\n",
       " ('宾', 'O'),\n",
       " ('出', 'O'),\n",
       " ('现', 'O'),\n",
       " ('在', 'O'),\n",
       " ('演', 'O'),\n",
       " ('唱', 'O'),\n",
       " ('会', 'O'),\n",
       " ('上', 'O')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"马苏、周冬雨、林更新、霍建华都被拍到出现在周杰伦的演唱会上，此外，林俊杰和陈奕迅等超级巨星也都作为演唱会嘉宾出现在演唱会上\"\n",
    "_X, _length = ner.sentence_encode(s)\n",
    "fd = {X: _X, length: _length, dropout: 1.}\n",
    "result = sess.run(logists, feed_dict=fd)\n",
    "result_entities = ner.entities_decode(result[0].argmax(axis=1))\n",
    "list(zip(s, result_entities))[:_length[0]][:len(s)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PbCPhxHVrxeb"
   },
   "source": [
    "### Section 2: train a model [1. from scratch, 2. incremental training]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SLF1OFPOlbp0",
    "outputId": "706ddc06-6498-4e42-8049-93c7f1a7976c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载语料./data/example.train, 语料数量18404\n",
      "成功加载语料./data/example.test, 语料数量4558\n",
      "成功加载语料./data/example.dev, 语料数量4384\n",
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:28: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:28: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:36: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:31: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/ma-user/work/elmo.py:56: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff67174df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff67174df98>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff67174df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff67174df98>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff6855f3780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff6855f3780>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff6855f3780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff6855f3780>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff69f6df5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff69f6df5f8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff69f6df5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff69f6df5f8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff671504ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff671504ba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff671504ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff671504ba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model2/model2-1421\n",
      "create the directory: ./model3\n",
      "no checkpoint found!\n",
      "epoch: 0 step: 0 loss: 0.01298594355583191\n",
      "平均每句有标注的实体数: 0.0\n",
      "test_loss: 1.3244393\n",
      "epoch: 0 step: 100 loss: 1.3893569839000701\n",
      "epoch: 1 step: 200 loss: 1.3870367646217345\n",
      "epoch: 2 step: 300 loss: 1.3862253046035766\n",
      "epoch: 2 step: 400 loss: 1.3915900087356567\n",
      "epoch: 3 step: 500 loss: 1.3905113565921783\n",
      "epoch: 4 step: 600 loss: 1.3886579430103303\n",
      "epoch: 4 step: 700 loss: 1.395386253595352\n",
      "epoch: 5 step: 800 loss: 1.3849457919597625\n",
      "epoch: 6 step: 900 loss: 1.3865033030509948\n",
      "epoch: 6 step: 1000 loss: 1.3955989742279054\n",
      "平均每句有标注的实体数: 0.0\n",
      "test_loss: 1.3388772\n",
      "epoch: 7 step: 1100 loss: 1.3879157865047456\n",
      "epoch: 8 step: 1200 loss: 1.3869520771503447\n",
      "epoch: 9 step: 1300 loss: 1.3871562731266023\n",
      "epoch: 9 step: 1400 loss: 1.391118230819702\n",
      "epoch: 10 step: 1500 loss: 1.3904159700870513\n",
      "epoch: 11 step: 1600 loss: 1.3884122943878174\n",
      "epoch: 11 step: 1700 loss: 1.3949502670764924\n",
      "epoch: 12 step: 1800 loss: 1.3849979519844056\n",
      "epoch: 13 step: 1900 loss: 1.3863831877708435\n",
      "epoch: 13 step: 2000 loss: 1.3957663106918334\n",
      "平均每句有标注的实体数: 0.0\n",
      "test_loss: 1.3618705\n",
      "epoch: 14 step: 2100 loss: 1.3870082533359527\n",
      "epoch: 15 step: 2200 loss: 1.3862685120105744\n",
      "epoch: 16 step: 2300 loss: 1.3880457925796508\n",
      "epoch: 16 step: 2400 loss: 1.3914434313774109\n",
      "epoch: 17 step: 2500 loss: 1.3900437998771666\n",
      "epoch: 18 step: 2600 loss: 1.3881500923633576\n",
      "epoch: 18 step: 2700 loss: 1.3937199306488037\n",
      "epoch: 19 step: 2800 loss: 1.3854720747470857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 step: 2900 loss: 1.3872063338756562\n",
      "epoch: 20 step: 3000 loss: 1.3946579587459564\n",
      "平均每句有标注的实体数: 0.0\n",
      "test_loss: 1.4042026\n",
      "epoch: 21 step: 3100 loss: 1.38686643242836\n",
      "epoch: 22 step: 3200 loss: 1.3861156606674194\n",
      "epoch: 23 step: 3300 loss: 1.3882762265205384\n",
      "epoch: 23 step: 3400 loss: 1.391923747062683\n",
      "epoch: 24 step: 3500 loss: 1.3897809720039367\n",
      "epoch: 25 step: 3600 loss: 1.388321019411087\n",
      "epoch: 25 step: 3700 loss: 1.392163075208664\n",
      "epoch: 26 step: 3800 loss: 1.3863803148269653\n",
      "epoch: 27 step: 3900 loss: 1.3863626873493196\n",
      "epoch: 27 step: 4000 loss: 1.3956758236885072\n",
      "平均每句有标注的实体数: 0.0\n",
      "test_loss: 1.4033378\n",
      "epoch: 28 step: 4100 loss: 1.3859070456027984\n",
      "epoch: 29 step: 4200 loss: 1.3860981273651123\n",
      "epoch: 30 step: 4300 loss: 1.3890169215202333\n",
      "epoch: 30 step: 4400 loss: 1.3918448448181153\n",
      "epoch: 31 step: 4500 loss: 1.3895723795890809\n",
      "epoch: 32 step: 4600 loss: 1.3882213723659516\n",
      "epoch: 32 step: 4700 loss: 1.3921224665641785\n",
      "epoch: 33 step: 4800 loss: 1.3859326136112213\n",
      "epoch: 34 step: 4900 loss: 1.386021009683609\n",
      "epoch: 34 step: 5000 loss: 1.3963715136051178\n",
      "平均每句有标注的实体数: 0.0\n",
      "test_loss: 1.3761755\n",
      "epoch: 35 step: 5100 loss: 1.3849296545982361\n",
      "epoch: 36 step: 5200 loss: 1.386270810365677\n",
      "epoch: 37 step: 5300 loss: 1.3896763825416565\n",
      "epoch: 37 step: 5400 loss: 1.3918419921398162\n",
      "epoch: 38 step: 5500 loss: 1.3894141280651093\n",
      "epoch: 39 step: 5600 loss: 1.3878009927272796\n",
      "epoch: 39 step: 5700 loss: 1.3913668167591096\n",
      "epoch: 40 step: 5800 loss: 1.3866099548339843\n",
      "epoch: 41 step: 5900 loss: 1.3864899325370788\n",
      "epoch: 41 step: 6000 loss: 1.3960933411121368\n",
      "平均每句有标注的实体数: 0.0\n",
      "test_loss: 1.3773184\n",
      "epoch: 42 step: 6100 loss: 1.3847016632556914\n",
      "epoch: 43 step: 6200 loss: 1.3863878011703492\n",
      "epoch: 44 step: 6300 loss: 1.3897751796245574\n",
      "epoch: 44 step: 6400 loss: 1.3922054839134217\n",
      "epoch: 45 step: 6500 loss: 1.3888099884986878\n",
      "epoch: 46 step: 6600 loss: 1.3878593754768371\n",
      "epoch: 46 step: 6700 loss: 1.3902448320388794\n",
      "epoch: 47 step: 6800 loss: 1.3876916062831879\n",
      "epoch: 48 step: 6900 loss: 1.386735475063324\n",
      "epoch: 48 step: 7000 loss: 1.3959044802188874\n",
      "平均每句有标注的实体数: 0.0\n",
      "test_loss: 1.4013593\n",
      "epoch: 49 step: 7100 loss: 1.3842125916481018\n",
      "epoch: 50 step: 7200 loss: 1.386151568889618\n",
      "epoch: 51 step: 7300 loss: 1.3907510590553285\n",
      "epoch: 51 step: 7400 loss: 1.3917757511138915\n",
      "epoch: 52 step: 7500 loss: 1.3890260827541352\n",
      "epoch: 53 step: 7600 loss: 1.3868381559848786\n",
      "epoch: 53 step: 7700 loss: 1.3901706266403198\n",
      "epoch: 54 step: 7800 loss: 1.3882850503921509\n",
      "epoch: 55 step: 7900 loss: 1.3867479324340821\n",
      "epoch: 55 step: 8000 loss: 1.3964708018302918\n",
      "平均每句有标注的实体数: 0.0\n",
      "test_loss: 1.4007881\n",
      "epoch: 56 step: 8100 loss: 1.3838121700286865\n",
      "epoch: 57 step: 8200 loss: 1.3853254294395447\n",
      "epoch: 58 step: 8300 loss: 1.390476907491684\n",
      "epoch: 58 step: 8400 loss: 1.3833083033561706\n",
      "epoch: 59 step: 8500 loss: 1.375201791524887\n",
      "epoch: 60 step: 8600 loss: 1.3698824810981751\n",
      "epoch: 60 step: 8700 loss: 1.3714619553089142\n",
      "epoch: 61 step: 8800 loss: 1.3626040720939636\n",
      "epoch: 62 step: 8900 loss: 1.3487862598896028\n",
      "epoch: 62 step: 9000 loss: 1.3463423466682434\n",
      "平均每句有标注的实体数: 2.296875\n",
      "test_loss: 1.3408903\n",
      "epoch: 63 step: 9100 loss: 1.3428467011451721\n",
      "epoch: 64 step: 9200 loss: 1.3367146480083465\n",
      "epoch: 65 step: 9300 loss: 1.3390222811698913\n",
      "epoch: 65 step: 9400 loss: 1.3414070403575897\n",
      "epoch: 66 step: 9500 loss: 1.336509655714035\n",
      "epoch: 67 step: 9600 loss: 1.3332588326931\n",
      "epoch: 67 step: 9700 loss: 1.3262670850753784\n",
      "epoch: 68 step: 9800 loss: 1.314779931306839\n",
      "epoch: 69 step: 9900 loss: 1.3077592074871063\n",
      "epoch: 69 step: 10000 loss: 1.3065473306179047\n",
      "平均每句有标注的实体数: 6.9921875\n",
      "test_loss: 1.326141\n",
      "epoch: 70 step: 10100 loss: 1.3019437789916992\n",
      "epoch: 71 step: 10200 loss: 1.2999638605117798\n",
      "epoch: 72 step: 10300 loss: 1.3002491116523742\n",
      "epoch: 72 step: 10400 loss: 1.2989412236213684\n",
      "epoch: 73 step: 10500 loss: 1.2971167171001434\n",
      "epoch: 74 step: 10600 loss: 1.2955516636371613\n",
      "epoch: 74 step: 10700 loss: 1.2948587107658387\n",
      "epoch: 75 step: 10800 loss: 1.2939135837554931\n",
      "epoch: 76 step: 10900 loss: 1.2928812289237976\n",
      "epoch: 76 step: 11000 loss: 1.2930012512207032\n",
      "平均每句有标注的实体数: 5.890625\n",
      "test_loss: 1.3109187\n",
      "epoch: 77 step: 11100 loss: 1.2914913403987884\n",
      "epoch: 78 step: 11200 loss: 1.2903919517993927\n",
      "epoch: 79 step: 11300 loss: 1.2908512616157533\n",
      "epoch: 79 step: 11400 loss: 1.2906691193580628\n",
      "epoch: 80 step: 11500 loss: 1.2892631554603577\n",
      "epoch: 81 step: 11600 loss: 1.2891775512695312\n",
      "epoch: 81 step: 11700 loss: 1.288754620552063\n",
      "epoch: 82 step: 11800 loss: 1.288298842906952\n",
      "epoch: 83 step: 11900 loss: 1.2880062985420226\n",
      "epoch: 83 step: 12000 loss: 1.2881318235397339\n",
      "平均每句有标注的实体数: 7.2734375\n",
      "test_loss: 1.304429\n",
      "epoch: 84 step: 12100 loss: 1.2872819328308105\n",
      "epoch: 85 step: 12200 loss: 1.2867325067520141\n",
      "epoch: 86 step: 12300 loss: 1.2870372474193572\n",
      "epoch: 86 step: 12400 loss: 1.287101684808731\n",
      "epoch: 87 step: 12500 loss: 1.2864036166667938\n",
      "epoch: 88 step: 12600 loss: 1.2863442552089692\n",
      "epoch: 88 step: 12700 loss: 1.2861637997627258\n",
      "epoch: 89 step: 12800 loss: 1.285715070962906\n",
      "epoch: 90 step: 12900 loss: 1.285672641992569\n",
      "epoch: 90 step: 13000 loss: 1.285640777349472\n",
      "平均每句有标注的实体数: 4.390625\n",
      "test_loss: 1.3076981\n",
      "epoch: 91 step: 13100 loss: 1.2850809621810912\n",
      "epoch: 92 step: 13200 loss: 1.2848360967636108\n",
      "epoch: 93 step: 13300 loss: 1.2849506986141206\n",
      "epoch: 93 step: 13400 loss: 1.2851774430274963\n",
      "epoch: 94 step: 13500 loss: 1.284338755607605\n",
      "epoch: 95 step: 13600 loss: 1.2843646538257598\n",
      "epoch: 95 step: 13700 loss: 1.284389661550522\n",
      "epoch: 96 step: 13800 loss: 1.28394855260849\n",
      "epoch: 97 step: 13900 loss: 1.2840551471710204\n",
      "epoch: 97 step: 14000 loss: 1.284107607603073\n",
      "平均每句有标注的实体数: 2.765625\n",
      "test_loss: 1.297653\n",
      "epoch: 98 step: 14100 loss: 1.2835080480575563\n",
      "epoch: 99 step: 14200 loss: 1.2832724940776825\n",
      "epoch: 100 step: 14300 loss: 1.2836794912815095\n",
      "saving...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import seq2seq\n",
    "from elmo import ELMo\n",
    "from data import NERData\n",
    "import os\n",
    "\n",
    "total_epoch = 100\n",
    "hidden_size = 200\n",
    "vocab_size = 5000\n",
    "max_length = 128\n",
    "entity_class = 7\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "\n",
    "ner = NERData(batch_size, max_length)\n",
    "elmo = ELMo(batch_size, hidden_size, vocab_size)\n",
    "\n",
    "\n",
    "def network(X):\n",
    "    w = tf.get_variable(\"fcn_w\", [1, hidden_size, entity_class + 1])\n",
    "    b = tf.get_variable(\"fcn_b\", [entity_class + 1])\n",
    "    # 这里输出维度用entity_class + 1而不是entity_class，因为输出里除了7类实体，还有一类用来表示每个句子补齐的<PAD>位\n",
    "    w_tile = tf.tile(w, [batch_size, 1, 1])\n",
    "\n",
    "    logists = tf.nn.softmax(tf.nn.xw_plus_b(X, w_tile, b), name=\"logists\")\n",
    "    return logists\n",
    "\n",
    "\n",
    "def train():\n",
    "    X = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"X\")\n",
    "    length = tf.placeholder(shape=[batch_size], dtype=tf.int32, name=\"length\")\n",
    "    targets = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"targets\")\n",
    "    weights = tf.placeholder(shape=[batch_size, max_length], dtype=tf.float32, name=\"weights\")\n",
    "    dropout = tf.placeholder(shape=[], dtype=tf.float32, name=\"dropout\")\n",
    "\n",
    "    elmo_vector = elmo.elmo(X, length, dropout)\n",
    "    logists = network(elmo_vector)\n",
    "\n",
    "    seq_loss = seq2seq.sequence_loss(logists, targets, weights)\n",
    "    # optimizer = tf.train.AdamOptimizer(lr).minimize(seq_loss)\n",
    "\n",
    "    trainableVariables = tf.trainable_variables()\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    grads, a = tf.clip_by_global_norm(tf.gradients(seq_loss, trainableVariables), 5)\n",
    "    train_op = optimizer.apply_gradients(zip(grads, trainableVariables))\n",
    "\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "    config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        model_dir = \"model1\"\n",
    "        saver = tf.train.Saver(max_to_keep=10)\n",
    "        if not os.path.exists(model_dir):   # 检查./model路径是否存在\n",
    "            os.mkdir(model_dir)             # 不存在就创建路径\n",
    "            print(\"create the directory: %s\" % model_dir)\n",
    "        check_point = tf.train.get_checkpoint_state(model_dir)\n",
    "        if check_point and check_point.model_checkpoint_path:\n",
    "            saver.restore(sess, check_point.model_checkpoint_path)\n",
    "            print(\"restored %s\" % check_point.model_checkpoint_path)\n",
    "        else:\n",
    "            print(\"no checkpoint found!\")\n",
    "\n",
    "        step = 0\n",
    "        total_loss = 0\n",
    "        while ner.epoch < total_epoch:\n",
    "            _X, _length, _targets, _weights = ner.get_train_batch()\n",
    "            fd = {X: _X, length: _length, targets: _targets, weights: _weights, dropout: .75}\n",
    "            _, l = sess.run([train_op, seq_loss], feed_dict=fd)\n",
    "            total_loss += l\n",
    "            if step % 100 == 0:\n",
    "                print(\"epoch:\", ner.epoch, \"step:\", step, \"loss:\", total_loss / 100)\n",
    "                total_loss = 0\n",
    "\n",
    "            if step % 1000 == 0:\n",
    "                _X, _length, _targets, _weights = ner.get_test_batch()\n",
    "                fd = {X: _X, length: _length, targets: _targets, weights: _weights, dropout: 1.}\n",
    "                l, result = sess.run([seq_loss, logists], feed_dict=fd)\n",
    "                result = result.argmax(axis=2)\n",
    "                ner_num = 0\n",
    "                for i in range(batch_size):\n",
    "                    for j in range(_length[i]):\n",
    "                        if result[i, j] != 1:\n",
    "                            ner_num += 1\n",
    "                print(\"平均每句有标注的实体数:\", ner_num / batch_size)\n",
    "                print(\"test_loss:\", l)\n",
    "\n",
    "#             if step % 10000 == 0:\n",
    "            step += 1\n",
    "        saver.save(sess, model_dir, global_step=step)  # 保存模型\n",
    "        print(\"saving...\")\n",
    "\n",
    "            \n",
    "def incremental_train():\n",
    "    X = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"X\")\n",
    "    length = tf.placeholder(shape=[batch_size], dtype=tf.int32, name=\"length\")\n",
    "    targets = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"targets\")\n",
    "    weights = tf.placeholder(shape=[batch_size, max_length], dtype=tf.float32, name=\"weights\")\n",
    "    dropout = tf.placeholder(shape=[], dtype=tf.float32, name=\"dropout\")\n",
    "#     dropout = tf.placeholder(shape=[], dtype=tf.float32, name=\"dropout\")\n",
    "\n",
    "    elmo_vector = elmo.elmo(X, length, dropout)\n",
    "    logists = network(elmo_vector)\n",
    "\n",
    "    seq_loss = seq2seq.sequence_loss(logists, targets, weights)\n",
    "    # optimizer = tf.train.AdamOptimizer(lr).minimize(seq_loss)\n",
    "\n",
    "    trainableVariables = tf.trainable_variables()\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    grads, a = tf.clip_by_global_norm(tf.gradients(seq_loss, trainableVariables), 5)\n",
    "    train_op = optimizer.apply_gradients(zip(grads, trainableVariables))\n",
    "    \n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "    config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    model_dir = \"./model2\"\n",
    "    saver = tf.train.Saver()\n",
    "    check_point = tf.train.get_checkpoint_state(model_dir)\n",
    "    saver.restore(sess, check_point.model_checkpoint_path)\n",
    "\n",
    "#     gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "#     config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "#     with tf.Session(config=config) as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "    model_dir = \"./model3\"\n",
    "    saver = tf.train.Saver(max_to_keep=10)\n",
    "    if not os.path.exists(model_dir):   # 检查./model路径是否存在\n",
    "        os.mkdir(model_dir)             # 不存在就创建路径\n",
    "        print(\"create the directory: %s\" % model_dir)\n",
    "    check_point = tf.train.get_checkpoint_state(model_dir)\n",
    "    if check_point and check_point.model_checkpoint_path:\n",
    "        saver.restore(sess,check_point.model_checkpoint_path)\n",
    "        print(\"restored %s\" % check_point.model_checkpoint_path)\n",
    "    else:\n",
    "        print(\"no checkpoint found!\")\n",
    "\n",
    "    step = 0\n",
    "    total_loss = 0\n",
    "    while ner.epoch < total_epoch:\n",
    "        _X, _length, _targets, _weights = ner.get_train_batch()\n",
    "        fd = {X: _X, length: _length, targets: _targets, weights: _weights, dropout: .75}\n",
    "        _, l = sess.run([train_op, seq_loss], feed_dict=fd)\n",
    "        total_loss += l\n",
    "        if step % 100 == 0:\n",
    "            print(\"epoch:\", ner.epoch, \"step:\", step, \"loss:\", total_loss / 100)\n",
    "            total_loss = 0\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            _X, _length, _targets, _weights = ner.get_test_batch()\n",
    "            fd = {X: _X, length: _length, targets: _targets, weights: _weights, dropout: 1.}\n",
    "            l, result = sess.run([seq_loss, logists], feed_dict=fd)\n",
    "            result = result.argmax(axis=2)\n",
    "            ner_num = 0\n",
    "            for i in range(batch_size):\n",
    "                for j in range(_length[i]):\n",
    "                    if result[i, j] != 1:\n",
    "                        ner_num += 1\n",
    "            print(\"平均每句有标注的实体数:\", ner_num / batch_size)\n",
    "            print(\"test_loss:\", l)\n",
    "\n",
    "#             if step % 10000 == 0:\n",
    "        step += 1\n",
    "    saver.save(sess, model_dir, global_step=step)  # 保存模型\n",
    "    print(\"saving...\")    \n",
    "\n",
    "    \n",
    "# 如果想from scratch 则使用函数train()\n",
    "# 如果想incrementally train 则使用函数incremental_train()\n",
    "if __name__ == \"__main__\":\n",
    "    incremental_train()\n",
    "#     train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 搬运操作可忽略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  data.py  elmo.py\tmodel1\tmodel2\tmodel3\t__pycache__\r\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv checkpoint model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.15.1-3fc51aac\n",
      "INFO:root:Using OBS-Python-SDK-3.1.2\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "mox.file.copy_parallel('/home/ma-user/work/model3', 'obs://class-1275-41780/Lab-1799/mode*******91/model3', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
