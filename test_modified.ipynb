{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "#### \u5907\u7528\u547d\u4ee4\u884c"}, {"metadata": {"collapsed": true, "trusted": false}, "cell_type": "code", "source": "!pip install tensorflow-gpu==1.13.1", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "Collecting tensorflow-gpu==1.13.1\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 345.2MB 82.7MB/s eta 0:00:01     | 37.0MB 86.9MB/s eta 0:00:04         | 56.4MB 82.2MB/s eta 0:00:04\u2588\u2588\u2588                          | 65.9MB 47.7MB/s eta 0:00:068MB 84.0MB/s eta 0:00:04 93.4MB 63.5MB/s eta 0:00:04\ufffd\ufffd\u2588\u2588\u2588\u2588\u258f                      | 98.9MB 64.4MB/s eta 0:00:04\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588                    | 130.4MB 102.8MB/s eta 0:00:0384.5MB/s eta 0:00:03\u2588\u2588\u2588\u258b                  | 146.4MB 98.6MB/s eta 0:00:03   44% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                 | 154.9MB 84.0MB/s eta 0:00:03   45% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                 | 158.0MB 67.8MB/s eta 0:00:03   | 165.7MB 86.1MB/s eta 0:00:03   52% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a               | 180.3MB 56.0MB/s eta 0:00:03\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588               | 184.1MB 72.4MB/s eta 0:00:03:02[K    55% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a              | 190.7MB 85.3MB/s eta 0:00:02[K    56% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588              | 195.0MB 51.1MB/s eta 0:00:03\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b             | 200.8MB 78.3MB/s eta 0:00:02 |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589           | 224.8MB 85.1MB/s eta 0:00:02 | 231.8MB 105.3MB/s eta 0:00:02s eta 0:00:02\u2588\u2588\u2588\u2588\u2588\u258a         | 245.4MB 77.8MB/s eta 0:00:02\u2588\u2588\u2588\u2588\u2588\u2588         | 248.9MB 64.1MB/s eta 0:00:0252.0MB 88.4MB/s eta 0:00:02\ufffd\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e    | 294.3MB 90.9MB/s eta 0:00:01\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 304.6MB 102.0MB/s eta 0:00:01.8MB 98.2MB/s eta 0:00:01\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 327.4MB 32.4MB/s eta 0:00:01\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 333.5MB 42.4MB/s eta 0:00:01\ufffd\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 342.7MB 50.3MB/s eta 0:00:01\n\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow-gpu==1.13.1)\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 368kB 102.7MB/s ta 0:00:01              | 204kB 102.2MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: gast>=0.2.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: absl-py>=0.1.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nCollecting tensorboard<1.14.0,>=1.13.0 (from tensorflow-gpu==1.13.1)\n  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.2MB 100.8MB/s ta 0:00:01   70% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a         | 2.3MB 72.8MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: grpcio>=1.8.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: keras-applications>=1.0.6 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: protobuf>=3.6.1 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: astor>=0.6.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: six>=1.10.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-gpu==1.13.1)\nRequirement already satisfied: mock>=2.0.0 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu==1.13.1)\nRequirement already satisfied: markdown>=2.6.8 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1)\nRequirement already satisfied: h5py in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1)\nRequirement already satisfied: setuptools in /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1)\nInstalling collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n  Found existing installation: tensorflow-estimator 1.14.0\n    Uninstalling tensorflow-estimator-1.14.0:\n      Successfully uninstalled tensorflow-estimator-1.14.0\n  Found existing installation: tensorboard 1.14.0\n    Uninstalling tensorboard-1.14.0:\n      Successfully uninstalled tensorboard-1.14.0\n  Found existing installation: tensorflow-gpu 1.14.0\n    Uninstalling tensorflow-gpu-1.14.0:\n      Successfully uninstalled tensorflow-gpu-1.14.0\nSuccessfully installed tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "!rm -f example.*", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "!rm -rf model2", "execution_count": 3, "outputs": []}, {"metadata": {"collapsed": true, "trusted": false}, "cell_type": "code", "source": "!cd model; dir", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "/bin/sh: line 0: cd: model: No such file or directory\r\ndata  data.py  elmo.py\tmodel1\t__pycache__\r\n", "name": "stdout"}]}, {"metadata": {"collapsed": true, "trusted": false}, "cell_type": "code", "source": "!dir ", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "data  data.py  elmo.py\tmodel3\t__pycache__\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### \u534e\u4e3a\u4e91\u642c\u8fd0\u6587\u4ef6\u81f3\u5f53\u524dnotebook dir"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "import moxing as mox\n\n# mox.file.copy_parallel('obs://class-1275-41780/Lab-1799/modelarts22888991/data', '/home/ma-user/work/data')\nmox.file.copy_parallel('obs://class-1275-41780/Lab-1799/modelarts22888991/model3', '/home/ma-user/work/model3')", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Section 1:  \u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u9884\u6d4b"}, {"metadata": {}, "cell_type": "markdown", "source": "#### step 1: \u5f15\u5165\u5305\uff0c\u53c2\u6570\u8bbe\u7f6e\uff0c\u7c7b\u52a0\u8f7d\n\n> \u9700\u8981\u5c06emlo.py \u548c data.py \u4e24\u4e2a\u6587\u4ef6\u653e\u5728\u540c\u76ee\u5f55\u4e0b                  \n> \u9700\u8981\u5c06data\u6587\u4ef6\u5939\u653e\u5728\u540c\u76ee\u5f55\u4e0b"}, {"metadata": {"id": "6kik532ElbpO", "colab_type": "code", "colab": {"base_uri": "https://localhost:8080/", "height": 398}, "outputId": "6f057f32-f494-4fa5-92f5-e0cc6715feb2", "trusted": false}, "cell_type": "code", "source": "import tensorflow as tf\nfrom tensorflow.contrib import seq2seq\nfrom elmo import ELMo\nfrom data import NERData\nimport os\n\ntotal_epoch = 5000\nhidden_size = 200\nvocab_size = 5000\nmax_length = 128\nentity_class = 7\n\nbatch_size = 1    # \u8ddf\u8bad\u7ec3\u7684\u533a\u522b\n\nner = NERData(batch_size, max_length)\nelmo = ELMo(batch_size, hidden_size, vocab_size)", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "\u6210\u529f\u52a0\u8f7d\u8bed\u6599./data/example.train, \u8bed\u6599\u6570\u91cf18404\n\u6210\u529f\u52a0\u8f7d\u8bed\u6599./data/example.test, \u8bed\u6599\u6570\u91cf4558\n\u6210\u529f\u52a0\u8f7d\u8bed\u6599./data/example.dev, \u8bed\u6599\u6570\u91cf4384\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### step 2: \u9876\u5c42softmax layer\u51fd\u6570\u5b9a\u4e49"}, {"metadata": {"id": "twFdg_xMlbpV", "colab_type": "code", "colab": {}, "trusted": false}, "cell_type": "code", "source": "def network(X):\n#     with tf.variable_scope(reuse=tf.AUTO_REUSE):\n        w = tf.get_variable(\"fcn_w\", [1, hidden_size, entity_class + 1])\n        b = tf.get_variable(\"fcn_b\", [entity_class + 1])\n        # \u8fd9\u91cc\u8f93\u51fa\u7ef4\u5ea6\u7528entity_class + 1\u800c\u4e0d\u662fentity_class\uff0c\u56e0\u4e3a\u8f93\u51fa\u91cc\u9664\u4e867\u7c7b\u5b9e\u4f53\uff0c\u8fd8\u6709\u4e00\u7c7b\u7528\u6765\u8868\u793a\u6bcf\u4e2a\u53e5\u5b50\u8865\u9f50\u7684<PAD>\u4f4d\n        w_tile = tf.tile(w, [batch_size, 1, 1])\n\n        logists = tf.nn.softmax(tf.nn.xw_plus_b(X, w_tile, b), name=\"logists\")\n        return logists", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### step 3: \u8f7d\u5165\u6a21\u578b"}, {"metadata": {"id": "C_HCR-RKlbpZ", "colab_type": "code", "colab": {}, "collapsed": true, "trusted": false}, "cell_type": "code", "source": "X = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"X\")\nlength = tf.placeholder(shape=[batch_size], dtype=tf.int32, name=\"length\")\ndropout = tf.placeholder(shape=[], dtype=tf.float32, name=\"dropout\")\n\nelmo_vector = elmo.elmo(X, length, dropout)\nlogists = network(elmo_vector)\n\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\nconfig = tf.ConfigProto(gpu_options=gpu_options)\nsess = tf.Session(config=config)\n\nsess.run(tf.global_variables_initializer())\nmodel_dir = \"./model3\"\nsaver = tf.train.Saver()\ncheck_point = tf.train.get_checkpoint_state(model_dir)\nsaver.restore(sess, check_point.model_checkpoint_path)", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "WARNING:tensorflow:From /home/ma-user/work/elmo.py:28: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n\nWARNING:tensorflow:From /home/ma-user/work/elmo.py:28: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n\nWARNING:tensorflow:From /home/ma-user/work/elmo.py:36: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n\nWARNING:tensorflow:From /home/ma-user/work/elmo.py:31: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\nWARNING:tensorflow:From /home/ma-user/work/elmo.py:56: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `keras.layers.RNN(cell)`, which is equivalent to this API\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f8a302d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f8a302d30>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f8a302d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f8a302d30>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f466cfcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f466cfcf8>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f466cfcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f466cfcf8>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f562fcb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f562fcb00>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f562fcb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f562fcb00>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f4494b518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f4494b518>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f4494b518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7f6f4494b518>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to check for files with this prefix.\nINFO:tensorflow:Restoring parameters from ./model3/model3-14301\n", "name": "stdout"}]}, {"metadata": {"id": "BnkfT4dalbpd", "colab_type": "text"}, "cell_type": "markdown", "source": "#### step 4: \u67e5\u770belmo\u5404\u5c42\u7684\u6743\u91cd"}, {"metadata": {"id": "7BbswS2glbpe", "colab_type": "code", "colab": {"base_uri": "https://localhost:8080/", "height": 104}, "outputId": "95d2ab2c-75ca-4713-a8e8-34a49cbabedf", "trusted": false}, "cell_type": "code", "source": "_X, _length, _targets = ner.get_dev_data(1)\nfd = {X: _X, length: _length, dropout: 1.}\nweights = sess.run(tf.nn.softmax(elmo.weights), feed_dict=fd)\nprint(\"embedding\u5c42:\", weights[0])\nprint(\"forward_1\u5c42:\", weights[1])\nprint(\"forward_2\u5c42:\", weights[2])\nprint(\"backward_1\u5c42:\", weights[3])\nprint(\"backward_2\u5c42:\", weights[4])", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "embedding\u5c42: 0.017066773\nforward_1\u5c42: 0.15887623\nforward_2\u5c42: 0.3802379\nbackward_1\u5c42: 0.23893026\nbackward_2\u5c42: 0.20488887\n", "name": "stdout"}]}, {"metadata": {"id": "ta5ZVr5tlbpi", "colab_type": "text"}, "cell_type": "markdown", "source": "#### step 5: \u7528\u6765\u81ea\u4e0d\u540c\u9886\u57df\u7684\u53e5\u5b50\u8fdb\u884c\u6d4b\u8bd5"}, {"metadata": {"id": "ucSPk56bo16J", "colab_type": "code", "colab": {"base_uri": "https://localhost:8080/", "height": 988}, "outputId": "36c32a8b-cf24-429f-bf36-8cc1f6822aed", "collapsed": true, "trusted": false}, "cell_type": "code", "source": "s = \"\u4e2d\u56fd\u77f3\u6cb9\u5927\u5b66\uff08\u5317\u4eac\uff09\u514b\u62c9\u739b\u4f9d\u6821\u533a\u8bbe\u6709\u77f3\u6cb9\u5de5\u7a0b\u3001\u5730\u8d28\u3001\u50a8\u8fd0\u7b49\u77f3\u6cb9\u5927\u5b66\u4f20\u7edf\u4f18\u52bf\u4e13\u4e1a\uff0c\u5e76\u5f00\u5c55\u9762\u5411\u4e2d\u4e9a\u5730\u533a\u7684\u7559\u5b66\u751f\u6559\u80b2\u3002\"\n_X, _length = ner.sentence_encode(s)\nfd = {X: _X, length: _length, dropout: 1.}\nresult = sess.run(logists, feed_dict=fd)\nresult_entities = ner.entities_decode(result[0].argmax(axis=1))\nlist(zip(s, result_entities))[:_length[0]][:len(s)]", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "[('\u4e2d', 'B-ORG'),\n ('\u56fd', 'I-ORG'),\n ('\u77f3', 'I-ORG'),\n ('\u6cb9', 'I-ORG'),\n ('\u5927', 'I-ORG'),\n ('\u5b66', 'I-ORG'),\n ('\uff08', 'O'),\n ('\u5317', 'B-LOC'),\n ('\u4eac', 'I-LOC'),\n ('\uff09', 'I-LOC'),\n ('\u514b', 'I-LOC'),\n ('\u62c9', 'I-LOC'),\n ('\u739b', 'I-PER'),\n ('\u4f9d', 'I-ORG'),\n ('\u6821', 'I-ORG'),\n ('\u533a', 'O'),\n ('\u8bbe', 'O'),\n ('\u6709', 'O'),\n ('\u77f3', 'O'),\n ('\u6cb9', 'O'),\n ('\u5de5', 'O'),\n ('\u7a0b', 'O'),\n ('\u3001', 'O'),\n ('\u5730', 'O'),\n ('\u8d28', 'O'),\n ('\u3001', 'O'),\n ('\u50a8', 'O'),\n ('\u8fd0', 'O'),\n ('\u7b49', 'O'),\n ('\u77f3', 'O'),\n ('\u6cb9', 'O'),\n ('\u5927', 'O'),\n ('\u5b66', 'O'),\n ('\u4f20', 'O'),\n ('\u7edf', 'O'),\n ('\u4f18', 'O'),\n ('\u52bf', 'O'),\n ('\u4e13', 'O'),\n ('\u4e1a', 'O'),\n ('\uff0c', 'O'),\n ('\u5e76', 'O'),\n ('\u5f00', 'O'),\n ('\u5c55', 'O'),\n ('\u9762', 'O'),\n ('\u5411', 'O'),\n ('\u4e2d', 'B-LOC'),\n ('\u4e9a', 'I-LOC'),\n ('\u5730', 'O'),\n ('\u533a', 'O'),\n ('\u7684', 'O'),\n ('\u7559', 'O'),\n ('\u5b66', 'O'),\n ('\u751f', 'O'),\n ('\u6559', 'O'),\n ('\u80b2', 'O'),\n ('\u3002', 'O')]"}, "metadata": {}}]}, {"metadata": {"id": "tewK8hsulbpj", "colab_type": "code", "colab": {"base_uri": "https://localhost:8080/", "height": 520}, "outputId": "32327085-0942-46c5-edd7-bd4dcbe37c3c", "collapsed": true, "trusted": false}, "cell_type": "code", "source": "s = \"\u674e\u514b\u5f3a\u6765\u5230\u4f4d\u4e8e\u6c5f\u897f\u7701\u8d63\u5dde\u5e02\u4e8e\u90fd\u53bf\u7684\u6893\u5c71\u9547\u6f6d\u5934\u6751\u770b\u671b\u6170\u95ee\u7fa4\u4f17\"\n_X, _length = ner.sentence_encode(s)\nfd = {X: _X, length: _length, dropout: 1.}\nresult = sess.run(logists, feed_dict=fd)\nresult_entities = ner.entities_decode(result[0].argmax(axis=1))\nlist(zip(s, result_entities))[:_length[0]][:len(s)]", "execution_count": 11, "outputs": [{"output_type": "execute_result", "execution_count": 11, "data": {"text/plain": "[('\u674e', 'B-PER'),\n ('\u514b', 'I-PER'),\n ('\u5f3a', 'I-PER'),\n ('\u6765', 'O'),\n ('\u5230', 'O'),\n ('\u4f4d', 'O'),\n ('\u4e8e', 'O'),\n ('\u6c5f', 'B-LOC'),\n ('\u897f', 'I-LOC'),\n ('\u7701', 'I-LOC'),\n ('\u8d63', 'B-LOC'),\n ('\u5dde', 'I-LOC'),\n ('\u5e02', 'I-LOC'),\n ('\u4e8e', 'O'),\n ('\u90fd', 'O'),\n ('\u53bf', 'B-LOC'),\n ('\u7684', 'O'),\n ('\u6893', 'B-LOC'),\n ('\u5c71', 'I-LOC'),\n ('\u9547', 'I-LOC'),\n ('\u6f6d', 'I-LOC'),\n ('\u5934', 'I-LOC'),\n ('\u6751', 'I-LOC'),\n ('\u770b', 'O'),\n ('\u671b', 'O'),\n ('\u6170', 'O'),\n ('\u95ee', 'O'),\n ('\u7fa4', 'O'),\n ('\u4f17', 'O')]"}, "metadata": {}}]}, {"metadata": {"id": "cVI7XZIBlbpn", "colab_type": "code", "colab": {}, "outputId": "f385b8fe-8d0e-4599-d996-64166bdedf7f", "collapsed": true, "trusted": false}, "cell_type": "code", "source": "s = \"\u591a\u540d\u767d\u5bab\u5b98\u5458\u5bf9\u5a92\u4f53\u8868\u793a\uff0c\u7f8e\u56fd\u603b\u7edf\u7279\u6717\u666e\u4e0d\u51c6\u5907\u7eed\u7b7e\u5373\u5c06\u5230\u671f\u7684\u7f8e\u4fc4\u300a\u65b0\u524a\u51cf\u6218\u7565\u6b66\u5668\u6761\u7ea6\u300b\uff0c\u800c\u662f\u60f3\u63a8\u52a8\u8fbe\u6210\u4e00\u9879\u5305\u62ec\u4e2d\u56fd\u5728\u5185\u7684\u65b0\u6761\u7ea6\"\n_X, _length = ner.sentence_encode(s)\nfd = {X: _X, length: _length, dropout: 1.}\nresult = sess.run(logists, feed_dict=fd)\nresult_entities = ner.entities_decode(result[0].argmax(axis=1))\nlist(zip(s, result_entities))[:_length[0]][:len(s)]", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "[('\u591a', 'O'),\n ('\u540d', 'O'),\n ('\u767d', 'B-ORG'),\n ('\u5bab', 'I-ORG'),\n ('\u5b98', 'O'),\n ('\u5458', 'O'),\n ('\u5bf9', 'O'),\n ('\u5a92', 'O'),\n ('\u4f53', 'O'),\n ('\u8868', 'O'),\n ('\u793a', 'O'),\n ('\uff0c', 'O'),\n ('\u7f8e', 'B-LOC'),\n ('\u56fd', 'I-LOC'),\n ('\u603b', 'O'),\n ('\u7edf', 'O'),\n ('\u7279', 'B-PER'),\n ('\u6717', 'I-LOC'),\n ('\u666e', 'I-PER'),\n ('\u4e0d', 'O'),\n ('\u51c6', 'O'),\n ('\u5907', 'O'),\n ('\u7eed', 'O'),\n ('\u7b7e', 'O'),\n ('\u5373', 'O'),\n ('\u5c06', 'O'),\n ('\u5230', 'O'),\n ('\u671f', 'O'),\n ('\u7684', 'O'),\n ('\u7f8e', 'B-LOC'),\n ('\u4fc4', 'B-LOC'),\n ('\u300a', 'O'),\n ('\u65b0', 'O'),\n ('\u524a', 'O'),\n ('\u51cf', 'O'),\n ('\u6218', 'O'),\n ('\u7565', 'O'),\n ('\u6b66', 'O'),\n ('\u5668', 'O'),\n ('\u6761', 'O'),\n ('\u7ea6', 'O'),\n ('\u300b', 'O'),\n ('\uff0c', 'O'),\n ('\u800c', 'O'),\n ('\u662f', 'O'),\n ('\u60f3', 'O'),\n ('\u63a8', 'O'),\n ('\u52a8', 'O'),\n ('\u8fbe', 'O'),\n ('\u6210', 'O'),\n ('\u4e00', 'O'),\n ('\u9879', 'O'),\n ('\u5305', 'O'),\n ('\u62ec', 'O'),\n ('\u4e2d', 'B-LOC'),\n ('\u56fd', 'I-LOC'),\n ('\u5728', 'O'),\n ('\u5185', 'O'),\n ('\u7684', 'O'),\n ('\u65b0', 'O'),\n ('\u6761', 'O'),\n ('\u7ea6', 'O')]"}, "metadata": {}}]}, {"metadata": {"id": "CgwS5TW2lbpr", "colab_type": "code", "colab": {}, "outputId": "f9d8236c-a9e0-4bdb-cfd0-01227567da5c", "collapsed": true, "trusted": false}, "cell_type": "code", "source": "s = \"\u5c0f\u7f57\u4f2f\u7279\u00b7\u5510\u5c3c\u4e13\u95e8\u4e3a\u6f2b\u5a01\u603b\u88c1\u51ef\u6587\u8d39\u5947\u9881\u53d1\u7279\u522b\u5927\u5956\uff0c\u4ed6\u5728\u4ecb\u7ecd\u51ef\u6587\u8d39\u5947\u7684\u65f6\u5019\u8bf4\u9053\u201c\u6211\u8981\u611f\u8c22\u51ef\u6587\uff0c\u4ed6\u5728\u6211\u7684\u4f4e\u8c37\u671f\u8ba4\u53ef\u6211\u201c\"\n_X, _length = ner.sentence_encode(s)\nfd = {X: _X, length: _length, dropout: 1.}\nresult = sess.run(logists, feed_dict=fd)\nresult_entities = ner.entities_decode(result[0].argmax(axis=1))\nlist(zip(s, result_entities))[:_length[0]][:len(s)]", "execution_count": 12, "outputs": [{"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "[('\u5c0f', 'B-PER'),\n ('\u7f57', 'B-PER'),\n ('\u4f2f', 'I-PER'),\n ('\u7279', 'I-PER'),\n ('\u00b7', 'I-PER'),\n ('\u5510', 'I-PER'),\n ('\u5c3c', 'I-PER'),\n ('\u4e13', 'O'),\n ('\u95e8', 'O'),\n ('\u4e3a', 'O'),\n ('\u6f2b', 'O'),\n ('\u5a01', 'O'),\n ('\u603b', 'O'),\n ('\u88c1', 'O'),\n ('\u51ef', 'B-PER'),\n ('\u6587', 'I-PER'),\n ('\u8d39', 'I-PER'),\n ('\u5947', 'I-PER'),\n ('\u9881', 'O'),\n ('\u53d1', 'O'),\n ('\u7279', 'O'),\n ('\u522b', 'O'),\n ('\u5927', 'O'),\n ('\u5956', 'O'),\n ('\uff0c', 'O'),\n ('\u4ed6', 'O'),\n ('\u5728', 'O'),\n ('\u4ecb', 'O'),\n ('\u7ecd', 'O'),\n ('\u51ef', 'B-PER'),\n ('\u6587', 'I-PER'),\n ('\u8d39', 'I-PER'),\n ('\u5947', 'I-PER'),\n ('\u7684', 'O'),\n ('\u65f6', 'O'),\n ('\u5019', 'O'),\n ('\u8bf4', 'O'),\n ('\u9053', 'O'),\n ('\u201c', 'O'),\n ('\u6211', 'O'),\n ('\u8981', 'O'),\n ('\u611f', 'O'),\n ('\u8c22', 'O'),\n ('\u51ef', 'O'),\n ('\u6587', 'O'),\n ('\uff0c', 'O'),\n ('\u4ed6', 'O'),\n ('\u5728', 'O'),\n ('\u6211', 'O'),\n ('\u7684', 'O'),\n ('\u4f4e', 'O'),\n ('\u8c37', 'O'),\n ('\u671f', 'O'),\n ('\u8ba4', 'O'),\n ('\u53ef', 'O'),\n ('\u6211', 'O'),\n ('\u201c', 'O')]"}, "metadata": {}}]}, {"metadata": {"id": "9FMLNbe-lbpv", "colab_type": "code", "colab": {}, "outputId": "73937453-dfb5-41e6-afc0-e37c96e013ae", "collapsed": true, "trusted": false}, "cell_type": "code", "source": "s = \"\u9a6c\u82cf\u3001\u5468\u51ac\u96e8\u3001\u6797\u66f4\u65b0\u3001\u970d\u5efa\u534e\u90fd\u88ab\u62cd\u5230\u51fa\u73b0\u5728\u5468\u6770\u4f26\u7684\u6f14\u5531\u4f1a\u4e0a\uff0c\u6b64\u5916\uff0c\u6797\u4fca\u6770\u548c\u9648\u5955\u8fc5\u7b49\u8d85\u7ea7\u5de8\u661f\u4e5f\u90fd\u4f5c\u4e3a\u6f14\u5531\u4f1a\u5609\u5bbe\u51fa\u73b0\u5728\u6f14\u5531\u4f1a\u4e0a\"\n_X, _length = ner.sentence_encode(s)\nfd = {X: _X, length: _length, dropout: 1.}\nresult = sess.run(logists, feed_dict=fd)\nresult_entities = ner.entities_decode(result[0].argmax(axis=1))\nlist(zip(s, result_entities))[:_length[0]][:len(s)]", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "[('\u9a6c', 'B-PER'),\n ('\u82cf', 'I-PER'),\n ('\u3001', 'O'),\n ('\u5468', 'B-PER'),\n ('\u51ac', 'I-PER'),\n ('\u96e8', 'I-PER'),\n ('\u3001', 'O'),\n ('\u6797', 'B-PER'),\n ('\u66f4', 'I-PER'),\n ('\u65b0', 'I-PER'),\n ('\u3001', 'O'),\n ('\u970d', 'B-PER'),\n ('\u5efa', 'I-PER'),\n ('\u534e', 'I-PER'),\n ('\u90fd', 'O'),\n ('\u88ab', 'O'),\n ('\u62cd', 'O'),\n ('\u5230', 'O'),\n ('\u51fa', 'O'),\n ('\u73b0', 'O'),\n ('\u5728', 'O'),\n ('\u5468', 'B-PER'),\n ('\u6770', 'I-PER'),\n ('\u4f26', 'I-PER'),\n ('\u7684', 'O'),\n ('\u6f14', 'O'),\n ('\u5531', 'O'),\n ('\u4f1a', 'O'),\n ('\u4e0a', 'O'),\n ('\uff0c', 'O'),\n ('\u6b64', 'O'),\n ('\u5916', 'O'),\n ('\uff0c', 'O'),\n ('\u6797', 'B-PER'),\n ('\u4fca', 'I-PER'),\n ('\u6770', 'I-PER'),\n ('\u548c', 'O'),\n ('\u9648', 'B-PER'),\n ('\u5955', 'I-PER'),\n ('\u8fc5', 'I-PER'),\n ('\u7b49', 'O'),\n ('\u8d85', 'O'),\n ('\u7ea7', 'O'),\n ('\u5de8', 'O'),\n ('\u661f', 'O'),\n ('\u4e5f', 'O'),\n ('\u90fd', 'O'),\n ('\u4f5c', 'O'),\n ('\u4e3a', 'O'),\n ('\u6f14', 'O'),\n ('\u5531', 'O'),\n ('\u4f1a', 'O'),\n ('\u5609', 'O'),\n ('\u5bbe', 'O'),\n ('\u51fa', 'O'),\n ('\u73b0', 'O'),\n ('\u5728', 'O'),\n ('\u6f14', 'O'),\n ('\u5531', 'O'),\n ('\u4f1a', 'O'),\n ('\u4e0a', 'O')]"}, "metadata": {}}]}, {"metadata": {"id": "PbCPhxHVrxeb", "colab_type": "text"}, "cell_type": "markdown", "source": "### Section 2: train a model [1. from scratch, 2. incremental training]"}, {"metadata": {"id": "SLF1OFPOlbp0", "colab_type": "code", "colab": {"base_uri": "https://localhost:8080/", "height": 374}, "outputId": "706ddc06-6498-4e42-8049-93c7f1a7976c", "collapsed": true, "trusted": false}, "cell_type": "code", "source": "import tensorflow as tf\nfrom tensorflow.contrib import seq2seq\nfrom elmo import ELMo\nfrom data import NERData\nimport os\n\ntotal_epoch = 100\nhidden_size = 200\nvocab_size = 5000\nmax_length = 128\nentity_class = 7\n\nlr = 1e-3\nbatch_size = 128\n\nner = NERData(batch_size, max_length)\nelmo = ELMo(batch_size, hidden_size, vocab_size)\n\n\ndef network(X):\n    w = tf.get_variable(\"fcn_w\", [1, hidden_size, entity_class + 1])\n    b = tf.get_variable(\"fcn_b\", [entity_class + 1])\n    # \u8fd9\u91cc\u8f93\u51fa\u7ef4\u5ea6\u7528entity_class + 1\u800c\u4e0d\u662fentity_class\uff0c\u56e0\u4e3a\u8f93\u51fa\u91cc\u9664\u4e867\u7c7b\u5b9e\u4f53\uff0c\u8fd8\u6709\u4e00\u7c7b\u7528\u6765\u8868\u793a\u6bcf\u4e2a\u53e5\u5b50\u8865\u9f50\u7684<PAD>\u4f4d\n    w_tile = tf.tile(w, [batch_size, 1, 1])\n\n    logists = tf.nn.softmax(tf.nn.xw_plus_b(X, w_tile, b), name=\"logists\")\n    return logists\n\n\ndef train():\n    X = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"X\")\n    length = tf.placeholder(shape=[batch_size], dtype=tf.int32, name=\"length\")\n    targets = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"targets\")\n    weights = tf.placeholder(shape=[batch_size, max_length], dtype=tf.float32, name=\"weights\")\n    dropout = tf.placeholder(shape=[], dtype=tf.float32, name=\"dropout\")\n\n    elmo_vector = elmo.elmo(X, length, dropout)\n    logists = network(elmo_vector)\n\n    seq_loss = seq2seq.sequence_loss(logists, targets, weights)\n    # optimizer = tf.train.AdamOptimizer(lr).minimize(seq_loss)\n\n    trainableVariables = tf.trainable_variables()\n    optimizer = tf.train.AdamOptimizer(lr)\n    grads, a = tf.clip_by_global_norm(tf.gradients(seq_loss, trainableVariables), 5)\n    train_op = optimizer.apply_gradients(zip(grads, trainableVariables))\n\n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n    config = tf.ConfigProto(gpu_options=gpu_options)\n\n    with tf.Session(config=config) as sess:\n        sess.run(tf.global_variables_initializer())\n        model_dir = \"model1\"\n        saver = tf.train.Saver(max_to_keep=10)\n        if not os.path.exists(model_dir):   # \u68c0\u67e5./model\u8def\u5f84\u662f\u5426\u5b58\u5728\n            os.mkdir(model_dir)             # \u4e0d\u5b58\u5728\u5c31\u521b\u5efa\u8def\u5f84\n            print(\"create the directory: %s\" % model_dir)\n        check_point = tf.train.get_checkpoint_state(model_dir)\n        if check_point and check_point.model_checkpoint_path:\n            saver.restore(sess, check_point.model_checkpoint_path)\n            print(\"restored %s\" % check_point.model_checkpoint_path)\n        else:\n            print(\"no checkpoint found!\")\n\n        step = 0\n        total_loss = 0\n        while ner.epoch < total_epoch:\n            _X, _length, _targets, _weights = ner.get_train_batch()\n            fd = {X: _X, length: _length, targets: _targets, weights: _weights, dropout: .75}\n            _, l = sess.run([train_op, seq_loss], feed_dict=fd)\n            total_loss += l\n            if step % 100 == 0:\n                print(\"epoch:\", ner.epoch, \"step:\", step, \"loss:\", total_loss / 100)\n                total_loss = 0\n\n            if step % 1000 == 0:\n                _X, _length, _targets, _weights = ner.get_test_batch()\n                fd = {X: _X, length: _length, targets: _targets, weights: _weights, dropout: 1.}\n                l, result = sess.run([seq_loss, logists], feed_dict=fd)\n                result = result.argmax(axis=2)\n                ner_num = 0\n                for i in range(batch_size):\n                    for j in range(_length[i]):\n                        if result[i, j] != 1:\n                            ner_num += 1\n                print(\"\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570:\", ner_num / batch_size)\n                print(\"test_loss:\", l)\n\n#             if step % 10000 == 0:\n            step += 1\n        saver.save(sess, model_dir, global_step=step)  # \u4fdd\u5b58\u6a21\u578b\n        print(\"saving...\")\n\n            \ndef incremental_train():\n    X = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"X\")\n    length = tf.placeholder(shape=[batch_size], dtype=tf.int32, name=\"length\")\n    targets = tf.placeholder(shape=[batch_size, max_length], dtype=tf.int32, name=\"targets\")\n    weights = tf.placeholder(shape=[batch_size, max_length], dtype=tf.float32, name=\"weights\")\n    dropout = tf.placeholder(shape=[], dtype=tf.float32, name=\"dropout\")\n#     dropout = tf.placeholder(shape=[], dtype=tf.float32, name=\"dropout\")\n\n    elmo_vector = elmo.elmo(X, length, dropout)\n    logists = network(elmo_vector)\n\n    seq_loss = seq2seq.sequence_loss(logists, targets, weights)\n    # optimizer = tf.train.AdamOptimizer(lr).minimize(seq_loss)\n\n    trainableVariables = tf.trainable_variables()\n    optimizer = tf.train.AdamOptimizer(lr)\n    grads, a = tf.clip_by_global_norm(tf.gradients(seq_loss, trainableVariables), 5)\n    train_op = optimizer.apply_gradients(zip(grads, trainableVariables))\n    \n    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n    config = tf.ConfigProto(gpu_options=gpu_options)\n    sess = tf.Session(config=config)\n\n    sess.run(tf.global_variables_initializer())\n    model_dir = \"./model2\"\n    saver = tf.train.Saver()\n    check_point = tf.train.get_checkpoint_state(model_dir)\n    saver.restore(sess, check_point.model_checkpoint_path)\n\n#     gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n#     config = tf.ConfigProto(gpu_options=gpu_options)\n\n#     with tf.Session(config=config) as sess:\n#         sess.run(tf.global_variables_initializer())\n    model_dir = \"./model3\"\n    saver = tf.train.Saver(max_to_keep=10)\n    if not os.path.exists(model_dir):   # \u68c0\u67e5./model\u8def\u5f84\u662f\u5426\u5b58\u5728\n        os.mkdir(model_dir)             # \u4e0d\u5b58\u5728\u5c31\u521b\u5efa\u8def\u5f84\n        print(\"create the directory: %s\" % model_dir)\n    check_point = tf.train.get_checkpoint_state(model_dir)\n    if check_point and check_point.model_checkpoint_path:\n        saver.restore(sess,check_point.model_checkpoint_path)\n        print(\"restored %s\" % check_point.model_checkpoint_path)\n    else:\n        print(\"no checkpoint found!\")\n\n    step = 0\n    total_loss = 0\n    while ner.epoch < total_epoch:\n        _X, _length, _targets, _weights = ner.get_train_batch()\n        fd = {X: _X, length: _length, targets: _targets, weights: _weights, dropout: .75}\n        _, l = sess.run([train_op, seq_loss], feed_dict=fd)\n        total_loss += l\n        if step % 100 == 0:\n            print(\"epoch:\", ner.epoch, \"step:\", step, \"loss:\", total_loss / 100)\n            total_loss = 0\n\n        if step % 1000 == 0:\n            _X, _length, _targets, _weights = ner.get_test_batch()\n            fd = {X: _X, length: _length, targets: _targets, weights: _weights, dropout: 1.}\n            l, result = sess.run([seq_loss, logists], feed_dict=fd)\n            result = result.argmax(axis=2)\n            ner_num = 0\n            for i in range(batch_size):\n                for j in range(_length[i]):\n                    if result[i, j] != 1:\n                        ner_num += 1\n            print(\"\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570:\", ner_num / batch_size)\n            print(\"test_loss:\", l)\n\n#             if step % 10000 == 0:\n        step += 1\n    saver.save(sess, model_dir, global_step=step)  # \u4fdd\u5b58\u6a21\u578b\n    print(\"saving...\")    \n\n    \n# \u5982\u679c\u60f3from scratch \u5219\u4f7f\u7528\u51fd\u6570train()\n# \u5982\u679c\u60f3incrementally train \u5219\u4f7f\u7528\u51fd\u6570incremental_train()\nif __name__ == \"__main__\":\n    incremental_train()\n#     train()", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "\u6210\u529f\u52a0\u8f7d\u8bed\u6599./data/example.train, \u8bed\u6599\u6570\u91cf18404\n\u6210\u529f\u52a0\u8f7d\u8bed\u6599./data/example.test, \u8bed\u6599\u6570\u91cf4558\n\u6210\u529f\u52a0\u8f7d\u8bed\u6599./data/example.dev, \u8bed\u6599\u6570\u91cf4384\nWARNING:tensorflow:From /home/ma-user/work/elmo.py:28: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n\nWARNING:tensorflow:From /home/ma-user/work/elmo.py:28: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n\nWARNING:tensorflow:From /home/ma-user/work/elmo.py:36: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n\nWARNING:tensorflow:From /home/ma-user/work/elmo.py:31: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\nWARNING:tensorflow:From /home/ma-user/work/elmo.py:56: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `keras.layers.RNN(cell)`, which is equivalent to this API\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff67174df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff67174df98>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff67174df98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff67174df98>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff6855f3780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff6855f3780>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff6855f3780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff6855f3780>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff69f6df5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff69f6df5f8>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff69f6df5f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff69f6df5f8>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff671504ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff671504ba8>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING: Entity <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff671504ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.LSTMCell object at 0x7ff671504ba8>>: AttributeError: module 'gast' has no attribute 'Num'\nWARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13.1/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to check for files with this prefix.\nINFO:tensorflow:Restoring parameters from ./model2/model2-1421\ncreate the directory: ./model3\nno checkpoint found!\nepoch: 0 step: 0 loss: 0.01298594355583191\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 0.0\ntest_loss: 1.3244393\nepoch: 0 step: 100 loss: 1.3893569839000701\nepoch: 1 step: 200 loss: 1.3870367646217345\nepoch: 2 step: 300 loss: 1.3862253046035766\nepoch: 2 step: 400 loss: 1.3915900087356567\nepoch: 3 step: 500 loss: 1.3905113565921783\nepoch: 4 step: 600 loss: 1.3886579430103303\nepoch: 4 step: 700 loss: 1.395386253595352\nepoch: 5 step: 800 loss: 1.3849457919597625\nepoch: 6 step: 900 loss: 1.3865033030509948\nepoch: 6 step: 1000 loss: 1.3955989742279054\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 0.0\ntest_loss: 1.3388772\nepoch: 7 step: 1100 loss: 1.3879157865047456\nepoch: 8 step: 1200 loss: 1.3869520771503447\nepoch: 9 step: 1300 loss: 1.3871562731266023\nepoch: 9 step: 1400 loss: 1.391118230819702\nepoch: 10 step: 1500 loss: 1.3904159700870513\nepoch: 11 step: 1600 loss: 1.3884122943878174\nepoch: 11 step: 1700 loss: 1.3949502670764924\nepoch: 12 step: 1800 loss: 1.3849979519844056\nepoch: 13 step: 1900 loss: 1.3863831877708435\nepoch: 13 step: 2000 loss: 1.3957663106918334\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 0.0\ntest_loss: 1.3618705\nepoch: 14 step: 2100 loss: 1.3870082533359527\nepoch: 15 step: 2200 loss: 1.3862685120105744\nepoch: 16 step: 2300 loss: 1.3880457925796508\nepoch: 16 step: 2400 loss: 1.3914434313774109\nepoch: 17 step: 2500 loss: 1.3900437998771666\nepoch: 18 step: 2600 loss: 1.3881500923633576\nepoch: 18 step: 2700 loss: 1.3937199306488037\nepoch: 19 step: 2800 loss: 1.3854720747470857\n", "name": "stdout"}, {"output_type": "stream", "text": "epoch: 20 step: 2900 loss: 1.3872063338756562\nepoch: 20 step: 3000 loss: 1.3946579587459564\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 0.0\ntest_loss: 1.4042026\nepoch: 21 step: 3100 loss: 1.38686643242836\nepoch: 22 step: 3200 loss: 1.3861156606674194\nepoch: 23 step: 3300 loss: 1.3882762265205384\nepoch: 23 step: 3400 loss: 1.391923747062683\nepoch: 24 step: 3500 loss: 1.3897809720039367\nepoch: 25 step: 3600 loss: 1.388321019411087\nepoch: 25 step: 3700 loss: 1.392163075208664\nepoch: 26 step: 3800 loss: 1.3863803148269653\nepoch: 27 step: 3900 loss: 1.3863626873493196\nepoch: 27 step: 4000 loss: 1.3956758236885072\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 0.0\ntest_loss: 1.4033378\nepoch: 28 step: 4100 loss: 1.3859070456027984\nepoch: 29 step: 4200 loss: 1.3860981273651123\nepoch: 30 step: 4300 loss: 1.3890169215202333\nepoch: 30 step: 4400 loss: 1.3918448448181153\nepoch: 31 step: 4500 loss: 1.3895723795890809\nepoch: 32 step: 4600 loss: 1.3882213723659516\nepoch: 32 step: 4700 loss: 1.3921224665641785\nepoch: 33 step: 4800 loss: 1.3859326136112213\nepoch: 34 step: 4900 loss: 1.386021009683609\nepoch: 34 step: 5000 loss: 1.3963715136051178\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 0.0\ntest_loss: 1.3761755\nepoch: 35 step: 5100 loss: 1.3849296545982361\nepoch: 36 step: 5200 loss: 1.386270810365677\nepoch: 37 step: 5300 loss: 1.3896763825416565\nepoch: 37 step: 5400 loss: 1.3918419921398162\nepoch: 38 step: 5500 loss: 1.3894141280651093\nepoch: 39 step: 5600 loss: 1.3878009927272796\nepoch: 39 step: 5700 loss: 1.3913668167591096\nepoch: 40 step: 5800 loss: 1.3866099548339843\nepoch: 41 step: 5900 loss: 1.3864899325370788\nepoch: 41 step: 6000 loss: 1.3960933411121368\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 0.0\ntest_loss: 1.3773184\nepoch: 42 step: 6100 loss: 1.3847016632556914\nepoch: 43 step: 6200 loss: 1.3863878011703492\nepoch: 44 step: 6300 loss: 1.3897751796245574\nepoch: 44 step: 6400 loss: 1.3922054839134217\nepoch: 45 step: 6500 loss: 1.3888099884986878\nepoch: 46 step: 6600 loss: 1.3878593754768371\nepoch: 46 step: 6700 loss: 1.3902448320388794\nepoch: 47 step: 6800 loss: 1.3876916062831879\nepoch: 48 step: 6900 loss: 1.386735475063324\nepoch: 48 step: 7000 loss: 1.3959044802188874\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 0.0\ntest_loss: 1.4013593\nepoch: 49 step: 7100 loss: 1.3842125916481018\nepoch: 50 step: 7200 loss: 1.386151568889618\nepoch: 51 step: 7300 loss: 1.3907510590553285\nepoch: 51 step: 7400 loss: 1.3917757511138915\nepoch: 52 step: 7500 loss: 1.3890260827541352\nepoch: 53 step: 7600 loss: 1.3868381559848786\nepoch: 53 step: 7700 loss: 1.3901706266403198\nepoch: 54 step: 7800 loss: 1.3882850503921509\nepoch: 55 step: 7900 loss: 1.3867479324340821\nepoch: 55 step: 8000 loss: 1.3964708018302918\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 0.0\ntest_loss: 1.4007881\nepoch: 56 step: 8100 loss: 1.3838121700286865\nepoch: 57 step: 8200 loss: 1.3853254294395447\nepoch: 58 step: 8300 loss: 1.390476907491684\nepoch: 58 step: 8400 loss: 1.3833083033561706\nepoch: 59 step: 8500 loss: 1.375201791524887\nepoch: 60 step: 8600 loss: 1.3698824810981751\nepoch: 60 step: 8700 loss: 1.3714619553089142\nepoch: 61 step: 8800 loss: 1.3626040720939636\nepoch: 62 step: 8900 loss: 1.3487862598896028\nepoch: 62 step: 9000 loss: 1.3463423466682434\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 2.296875\ntest_loss: 1.3408903\nepoch: 63 step: 9100 loss: 1.3428467011451721\nepoch: 64 step: 9200 loss: 1.3367146480083465\nepoch: 65 step: 9300 loss: 1.3390222811698913\nepoch: 65 step: 9400 loss: 1.3414070403575897\nepoch: 66 step: 9500 loss: 1.336509655714035\nepoch: 67 step: 9600 loss: 1.3332588326931\nepoch: 67 step: 9700 loss: 1.3262670850753784\nepoch: 68 step: 9800 loss: 1.314779931306839\nepoch: 69 step: 9900 loss: 1.3077592074871063\nepoch: 69 step: 10000 loss: 1.3065473306179047\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 6.9921875\ntest_loss: 1.326141\nepoch: 70 step: 10100 loss: 1.3019437789916992\nepoch: 71 step: 10200 loss: 1.2999638605117798\nepoch: 72 step: 10300 loss: 1.3002491116523742\nepoch: 72 step: 10400 loss: 1.2989412236213684\nepoch: 73 step: 10500 loss: 1.2971167171001434\nepoch: 74 step: 10600 loss: 1.2955516636371613\nepoch: 74 step: 10700 loss: 1.2948587107658387\nepoch: 75 step: 10800 loss: 1.2939135837554931\nepoch: 76 step: 10900 loss: 1.2928812289237976\nepoch: 76 step: 11000 loss: 1.2930012512207032\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 5.890625\ntest_loss: 1.3109187\nepoch: 77 step: 11100 loss: 1.2914913403987884\nepoch: 78 step: 11200 loss: 1.2903919517993927\nepoch: 79 step: 11300 loss: 1.2908512616157533\nepoch: 79 step: 11400 loss: 1.2906691193580628\nepoch: 80 step: 11500 loss: 1.2892631554603577\nepoch: 81 step: 11600 loss: 1.2891775512695312\nepoch: 81 step: 11700 loss: 1.288754620552063\nepoch: 82 step: 11800 loss: 1.288298842906952\nepoch: 83 step: 11900 loss: 1.2880062985420226\nepoch: 83 step: 12000 loss: 1.2881318235397339\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 7.2734375\ntest_loss: 1.304429\nepoch: 84 step: 12100 loss: 1.2872819328308105\nepoch: 85 step: 12200 loss: 1.2867325067520141\nepoch: 86 step: 12300 loss: 1.2870372474193572\nepoch: 86 step: 12400 loss: 1.287101684808731\nepoch: 87 step: 12500 loss: 1.2864036166667938\nepoch: 88 step: 12600 loss: 1.2863442552089692\nepoch: 88 step: 12700 loss: 1.2861637997627258\nepoch: 89 step: 12800 loss: 1.285715070962906\nepoch: 90 step: 12900 loss: 1.285672641992569\nepoch: 90 step: 13000 loss: 1.285640777349472\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 4.390625\ntest_loss: 1.3076981\nepoch: 91 step: 13100 loss: 1.2850809621810912\nepoch: 92 step: 13200 loss: 1.2848360967636108\nepoch: 93 step: 13300 loss: 1.2849506986141206\nepoch: 93 step: 13400 loss: 1.2851774430274963\nepoch: 94 step: 13500 loss: 1.284338755607605\nepoch: 95 step: 13600 loss: 1.2843646538257598\nepoch: 95 step: 13700 loss: 1.284389661550522\nepoch: 96 step: 13800 loss: 1.28394855260849\nepoch: 97 step: 13900 loss: 1.2840551471710204\nepoch: 97 step: 14000 loss: 1.284107607603073\n\u5e73\u5747\u6bcf\u53e5\u6709\u6807\u6ce8\u7684\u5b9e\u4f53\u6570: 2.765625\ntest_loss: 1.297653\nepoch: 98 step: 14100 loss: 1.2835080480575563\nepoch: 99 step: 14200 loss: 1.2832724940776825\nepoch: 100 step: 14300 loss: 1.2836794912815095\nsaving...\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### \u642c\u8fd0\u64cd\u4f5c\u53ef\u5ffd\u7565"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "!dir", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "data  data.py  elmo.py\tmodel1\tmodel2\tmodel3\t__pycache__\r\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "!mv checkpoint model3", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "import moxing as mox\nmox.file.copy_parallel('/home/ma-user/work/model3', 'obs://class-1275-41780/Lab-1799/modelarts22888991/model3', )", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "INFO:root:Using MoXing-v1.15.1-3fc51aac\nINFO:root:Using OBS-Python-SDK-3.1.2\n", "name": "stderr"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "tensorflow-1.13.1", "display_name": "TensorFlow-1.13.1", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "colab": {"name": "test.ipynb", "provenance": []}, "accelerator": "GPU"}, "nbformat": 4, "nbformat_minor": 1}